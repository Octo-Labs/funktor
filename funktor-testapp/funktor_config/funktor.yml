IncomingJobHandler:
  # timeout is how long the handler can possibly run. Up to 10 messages may be delivered
  # to a handler at one time, so you'll want this to be at least 10x the maximum time you
  # expect to spend for one message. The incoming job handler usually will be pretty fast,
  # but we default to a high number here to allow for the times when things go weird.
  timeout: 300
  # reservedConcurrency represents the maximum number of concurrent executions.
  # For the incoming job handler you probably don't want to limit it because you
  # want to get things onto work queues as quickly as possible.
  reservedConcurrency: null
  # provisionedConcurrency represents the number of lambda functions that will always
  # be available. For the incoming jobs handler you probably don't need to set this
  # unless your jobs are very bursty AND very time sensitive.
  provisionedConcurrency: null
  # Use memory_size to adjust the reousrces (both memory and CPU) available.
  # For the incoming jobs handler you probably don't need this to be too large,
  # but if you're seeing large delays at this stage it might help to bump it up.
  memorySize: 256
  batchSize: 10
  maximumBatchingWindow: 1
  visibilityTimeout: 900
  logRetentionInDays: 30

DefaultQueueHandler:
  # timeout is how long the handler can possibly run. Up to 10 messages may be delivered
  # to a handler at one time, so you'll want this to be at least 10x the maximum time you
  # expect to spend for one message. The active job handler may be slow if your jobs are
  # doing a lot of work, so we default to the maximum here.
  timeout: 300
  # reservedConcurrency represents the maximum number of concurrent executions.
  # For the active job handler you may want to limit it if you have resource limitations
  # like database connections that you need to avoid exhausting.
  reservedConcurrency: null
  # provisionedConcurrency represents the number of lambda functions that will always
  # be available. For the active job handler you probably don't need to set this
  # unless your jobs are very bursty AND very time sensitive.
  provisionedConcurrency: null
  # Use memory_size to adjust the reousrces (both memory and CPU) available.
  # For the active jobs handler you'll want this to be at least as large as the memory
  # required to actually do your jobs. You can choose an even higher number to increase
  # the available CPU to make the jobs run faster.
  memorySize: 256
  batchSize: 10
  maximumBatchingWindow: 1
  visibilityTimeout: 900
  logRetentionInDays: 30

SingleThreadQueueHandler:
  # timeout is how long the handler can possibly run. Up to 10 messages may be delivered
  # to a handler at one time, so you'll want this to be at least 10x the maximum time you
  # expect to spend for one message. The active job handler may be slow if your jobs are
  # doing a lot of work, so we default to the maximum here.
  timeout: 300
  # reservedConcurrency represents the maximum number of concurrent executions.
  # For the active job handler you may want to limit it if you have resource limitations
  # like database connections that you need to avoid exhausting.
  reservedConcurrency: 1
  # provisionedConcurrency represents the number of lambda functions that will always
  # be available. For the active job handler you probably don't need to set this
  # unless your jobs are very bursty AND very time sensitive.
  provisionedConcurrency: null
  # Use memory_size to adjust the reousrces (both memory and CPU) available.
  # For the active jobs handler you'll want this to be at least as large as the memory
  # required to actually do your jobs. You can choose an even higher number to increase
  # the available CPU to make the jobs run faster.
  memorySize: 256
  batchSize: 10
  maximumBatchingWindow: 1
  visibilityTimeout: 900
  logRetentionInDays: 30



# You shouldn't need to mess with these under most circumstances. But you could if you want to change
# the name of some of your resources in AWS.
IncomingJobQueueName: ${self:service}-${self:custom.stage}-incoming-jobs
IncomingDeadJobQueueName: ${self:service}-${self:custom.stage}-incoming-dead
IncomingJobHandlerName: ${self:service}-${self:custom.stage}-IncomingJobHandler
IncomingJobQueueAccessPolicyName: ${self:service}-${self:custom.stage}-incoming-job-queue-access
DashboardName: ${self:service}-${self:custom.stage}-dashboard
DefaultQueueName: ${self:service}-${self:custom.stage}-default
DefaultDeadJobQueueName: ${self:service}-${self:custom.stage}-default-dead
DefaultQueueHandlerName: ${self:service}-${self:custom.stage}-DefaultQueueHandler
SingleThreadQueueName: ${self:service}-${self:custom.stage}-single-thread
SingleThreadDeadJobQueueName: ${self:service}-${self:custom.stage}-single-thread-dead
SingleThreadQueueHandlerName: ${self:service}-${self:custom.stage}-SingleThreadQueueHandler


