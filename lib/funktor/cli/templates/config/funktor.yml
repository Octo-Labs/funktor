incomingJobHandler:
  # timeout is how long the handler can possibly run. Up to 10 messages may be delivered
  # to a handler at one time, so you'll want this to be at least 10x the maximum time you
  # expect to spend for one message. The incoming job handler usually will be pretty fast,
  # but we default to a high number here to allow for the times when things go weird.
  timeout: 300
  # reservedConcurrency represents the maximum number of concurrent executions.
  # For the incoming job handler you probably don't want to limit it because you
  # want to get things onto work queues as quickly as possible.
  reservedConcurrency: null
  # provisionedConcurrency represents the number of lambda functions that will always
  # be available. For the incoming jobs handler you probably don't need to set this
  # unless your jobs are very bursty AND very time sensitive.
  provisionedConcurrency: null
  # Use memory_size to adjust the reousrces (both memory and CPU) available.
  # For the incoming jobs handler you probably don't need this to be too large,
  # but if you're seeing large delays at this stage it might help to bump it up.
  memorySize: 256

activeJobHandler:
  # timeout is how long the handler can possibly run. Up to 10 messages may be delivered
  # to a handler at one time, so you'll want this to be at least 10x the maximum time you
  # expect to spend for one message. The active job handler may be slow if your jobs are
  # doing a lot of work, so we default to the maximum here.
  timeout: 300
  # reservedConcurrency represents the maximum number of concurrent executions.
  # For the active job handler you may want to limit it if you have resource limitations
  # like database connections that you need to avoid exhausting.
  reservedConcurrency: null
  # provisionedConcurrency represents the number of lambda functions that will always
  # be available. For the active job handler you probably don't need to set this
  # unless your jobs are very bursty AND very time sensitive.
  provisionedConcurrency: null
  # Use memory_size to adjust the reousrces (both memory and CPU) available.
  # For the active jobs handler you'll want this to be at least as large as the memory
  # required to actually do your jobs. You can choose an even higher number to increase
  # the available CPU to make the jobs run faster.
  memorySize: 256



# You shouldn't need to mess with these under most circumstances. But you could if you want to change
# the name of some of your resources in AWS.
incomingJobQueueName: ${self:service}-${self:custom.stage}-incoming-jobs
incomingJobQueueAccessPolicyName: ${self:service}-${self:custom.stage}-incoming-job-queue-access
incomingDeadJobQueueName: ${self:service}-${self:custom.stage}-incoming-dead-jobs
activeJobQueueName: ${self:service}-${self:custom.stage}-active-jobs
activityQueueName: ${self:service}-${self:custom.stage}-activity
activityDeadQueueName: ${self:service}-${self:custom.stage}-activity-dead
deadJobQueueName: ${self:service}-${self:custom.stage}-dead-jobs
dashboardName: ${self:service}-${self:custom.stage}-dashboard
